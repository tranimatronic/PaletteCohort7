{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importin Libraries\n",
    "\n",
    "import pandas as pd # Data manipulation\n",
    "import numpy as np # Matrix calculation\n",
    "import geopandas as gpd # GIS of Pandas\n",
    "import seaborn as sb # Parof of matplotlib for Data Viz\n",
    "import matplotlib.pyplot as plt # data viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL (Extract, Tranform, Load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Directories\n",
    "\n",
    "directory_main = '/users/ruhidmirzayev/palette/notebooks/cohort 6/'\n",
    "# Yield\n",
    "directory_rm_yields = directory_main + 'rm-yields-data.csv'\n",
    "#GIS\n",
    "directory_gis= directory_main + 'SK_RM_Shapefiles/RuralMunicipality.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Yields\n",
    "df_rm_yields=pd.read_csv(directory_rm_yields)\n",
    "# Reading GIS\n",
    "gdf_rm=gpd.read_file(directory_gis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rm_yields.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rm_yields.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rm_yields.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rm_yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_rm.plot() # good for GitHub"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Canola 30% - 99% of Canada is in Prairies\n",
    "# Wheat-Spring 30%\n",
    "# Peas\n",
    "# Oats\n",
    "# Lentils\n",
    "# Wheat-Durum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_major_crops=df_rm_yields[['Year', 'RM', 'Canola', 'Spring Wheat',\n",
    "       'Durum','Oats', 'Lentils', 'Peas', 'Barley']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_major_crops.describe().T\n",
    "# Spring wheat 198 - investigate\n",
    "# Oats 165 to invistigate\n",
    "# 4 digits Lentils to investigate - 1 bushel = 60 pounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Pounds to bushels\n",
    "df_major_crops['Lentils']=df_major_crops['Lentils']/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_major_crops.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_rm_clean=gdf_rm[['RMNO', 'RMNM', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf_rm_clean.info())\n",
    "print(df_major_crops.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to change Object to Int\n",
    "gdf_rm_clean['RMNO']=gdf_rm_clean['RMNO'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIS Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_rm_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changin CRS system to regular lon and lat\n",
    "gdf_rm_clean=gdf_rm_clean.to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_major_crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Yield data with GIS\n",
    "gdf_rm_yield=pd.merge(gdf_rm_clean.rename(columns={'RMNO':'RM'}), df_major_crops, on='RM', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at unique RM names for GIS data\n",
    "gdf_rm_yield['RM'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at unique RM names for yield data\n",
    "df_major_crops['RM'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot can be displayed in GitHub\n",
    "gdf_rm_yield[gdf_rm_yield['Year']==2021]\\\n",
    "    .plot(column='Canola',\n",
    "             cmap='Greens',\n",
    "             legend=True)\n",
    "plt.title('Canola Yield 2021', color='teal', size=16)\n",
    "plt.xticks(color='white')\n",
    "plt.yticks(color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of crops to include in plots\n",
    "crops = ['Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley', 'Canola']\n",
    "\n",
    "# List of years to include in subplots\n",
    "years = list(range(2004, 2023 + 1))\n",
    "\n",
    "# Function to plot yield data for a specific crop\n",
    "def plot_yield_by_year(crop):\n",
    "    # Set up the figure with 4 rows and 5 columns for the 20 subplots\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(20, 16))\n",
    "    fig.suptitle(f'{crop} Yield per Year (2004 - 2023)', color='teal', size=20)\n",
    "    \n",
    "    # Flatten the axs array for easy indexing\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Loop through each year and plot it on its respective subplot\n",
    "    for i, year in enumerate(years):\n",
    "        ax = axs[i]\n",
    "        gdf_rm_yield[gdf_rm_yield['Year'] == year].plot(\n",
    "            column=crop,\n",
    "            cmap='RdYlGn',\n",
    "            legend=False,\n",
    "            ax=ax,\n",
    "            edgecolor='black'\n",
    "        )\n",
    "        ax.set_title(f'Year: {year}', color='teal', size=12)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "    \n",
    "    # Adjust the spacing between subplots for readability\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Generate plots for each crop\n",
    "for crop in crops:\n",
    "    plot_yield_by_year(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crops - is a list defined in mapping cell\n",
    "# >0.2 slight correlation\n",
    "# >0.4 Moderate corrleation\n",
    "# > 0.6 High\n",
    "# > 0.8 Very correlation \n",
    "\n",
    "# Pearson Correlation\n",
    "sb.heatmap(df_major_crops.loc[df_major_crops['Year']>2003][crops].corr(),\n",
    "           annot=True,\n",
    "           cmap='RdYlGn')\n",
    "\n",
    "# Rank correlatation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before treating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for the years 2004-2023\n",
    "filtered_df = df_major_crops[(df_major_crops['Year'] >= 2004) & (df_major_crops['Year'] <= 2023)]\n",
    "\n",
    "# Define the list of crops\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(20, 16))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through the years and create a boxplot for each crop\n",
    "for i, year in enumerate(range(2004, 2023 + 1)):\n",
    "    if i < len(axes):\n",
    "        ax = axes[i]\n",
    "        year_data = filtered_df[filtered_df['Year'] == year]\n",
    "        year_data.boxplot(column=crops, ax=ax)\n",
    "        ax.set_title(f'Year: {year}', size=12, color='teal')\n",
    "        ax.tick_params(axis='x', rotation=30)  # Rotate x-tick labels\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After treating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of crops\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Calculate mean and standard deviation for each crop\n",
    "means = df_major_crops[crops].mean()\n",
    "stds = df_major_crops[crops].std()\n",
    "\n",
    "# Determine the clipping bounds\n",
    "lower_bounds = means - 3 * stds\n",
    "upper_bounds = means + 3 * stds\n",
    "\n",
    "# Clip the data\n",
    "df_clipped = df_major_crops.copy()\n",
    "for crop in crops:\n",
    "    df_clipped[crop] = df_major_crops[crop].clip(lower=lower_bounds[crop], upper=upper_bounds[crop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of crops\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(20, 16))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through the years and create a boxplot for each crop\n",
    "for i, year in enumerate(range(2004, 2023 + 1)):\n",
    "    if i < len(axes):\n",
    "        ax = axes[i]\n",
    "        year_data = df_clipped[df_clipped['Year'] == year]\n",
    "        year_data.boxplot(column=crops, ax=ax)\n",
    "        ax.set_title(f'Year: {year}', size=12, color='teal')\n",
    "        ax.tick_params(axis='x', rotation=30)  # Rotate x-tick labels\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Construction and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will filter years from 2000-2023\n",
    "\n",
    "df_00_23=df_major_crops[df_major_crops['Year']>=2000].drop(columns='decade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_00_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    gdf_rm_clean.rename(columns={'RMNO': 'RM'}),\n",
    "    df_00_23.groupby('RM').mean(),\n",
    "    on='RM').plot('Canola', cmap='RdYlGn', legend=True)\n",
    "plt.title('Historical Average | Canola')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(\n",
    "    gdf_rm_clean.rename(columns={'RMNO': 'RM'}),\n",
    "    df_00_23.groupby('RM').mean(),\n",
    "    on='RM'\n",
    ")\n",
    "\n",
    "# List of crops\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Create a subplot for each crop\n",
    "fig, axes = plt.subplots(nrows=len(crops), figsize=(10, 5 * len(crops)))\n",
    "\n",
    "# Plot each crop\n",
    "for i, crop in enumerate(crops):\n",
    "    merged_df.plot(column=crop, cmap='RdYlGn', legend=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Historical Average | {crop}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(\n",
    "    gdf_rm_clean.rename(columns={'RMNO': 'RM'}),\n",
    "    df_00_23.groupby('RM').std(),\n",
    "    on='RM'\n",
    ")\n",
    "\n",
    "# List of crops\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Create a subplot for each crop\n",
    "fig, axes = plt.subplots(nrows=len(crops), figsize=(10, 5 * len(crops)))\n",
    "\n",
    "# Plot each crop\n",
    "for i, crop in enumerate(crops):\n",
    "    merged_df.plot(column=crop, cmap='RdYlGn_r', legend=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Historical Average | {crop}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of crops\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Group by 'RM' and calculate mean and standard deviation for each crop\n",
    "df_agg_00_23 = df_00_23.groupby('RM')[crops].agg(['mean', 'std'])\n",
    "\n",
    "# Flatten the column multi-index\n",
    "df_agg_00_23.columns = ['_'.join(col).strip() for col in df_agg_00_23.columns.values]\n",
    "\n",
    "# Reset index to make 'RM' a column again\n",
    "df_agg_00_23.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Construction Completed\n",
    "# Mean and STD features are created\n",
    "df_agg_00_23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unsupervised ML - no train, not test and not validation dataset\n",
    "- We do not standardise or normalize , min/max scaler, bucketizing, data in this spesific dataset, because mean and std of crops are the same unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to bucketize the year into decades\n",
    "def bucketize_decade(year):\n",
    "    decade_start = (year // 10) * 10\n",
    "    decade_end = decade_start + 9\n",
    "    return f\"{decade_start}-{decade_end}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'decade' using the function\n",
    "df_major_crops['decade'] = df_major_crops['Year'].apply(bucketize_decade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "df_major_crops[crops+['decade']].groupby('decade').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Clusters recommeded by the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df_agg_00_23 is already loaded\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Function to prepare data for each crop\n",
    "def prepare_data_for_crop(df, crop):\n",
    "    columns = [f'{crop}_mean', f'{crop}_std']\n",
    "    crop_data = df[columns].dropna().values\n",
    "    return crop_data\n",
    "\n",
    "# Standardize the data\n",
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled\n",
    "\n",
    "# Function to perform spectral clustering and choose the optimal number of clusters\n",
    "def spectral_clustering(data, n_clusters):\n",
    "    clustering = SpectralClustering(n_clusters=n_clusters, assign_labels=\"discretize\", random_state=0)\n",
    "    labels = clustering.fit_predict(data)\n",
    "    return labels\n",
    "\n",
    "# Function to find the optimal number of clusters\n",
    "def find_optimal_clusters(data, max_k):\n",
    "    scores = []\n",
    "    for k in range(2, max_k+1):\n",
    "        labels = spectral_clustering(data, k)\n",
    "        score = silhouette_score(data, labels)\n",
    "        scores.append(score)\n",
    "    optimal_k = scores.index(max(scores)) + 2\n",
    "    return optimal_k, scores\n",
    "\n",
    "# Iterate over each crop and perform clustering\n",
    "for crop in crops:\n",
    "    # Prepare the data for the crop\n",
    "    crop_data = prepare_data_for_crop(df_agg_00_23, crop)\n",
    "    \n",
    "    # Standardize the data\n",
    "    crop_data_scaled = standardize_data(crop_data)\n",
    "    \n",
    "    # Find the optimal number of clusters\n",
    "    optimal_k, scores = find_optimal_clusters(crop_data_scaled, 10)\n",
    "    \n",
    "    # Perform spectral clustering with the optimal number of clusters\n",
    "    labels = spectral_clustering(crop_data_scaled, optimal_k)\n",
    "    \n",
    "    # Add the cluster labels to the original dataframe\n",
    "    df_agg_00_23[f'{crop}_Cluster'] = np.nan\n",
    "    df_agg_00_23.loc[~df_agg_00_23[[f'{crop}_mean', f'{crop}_std']].isna().any(axis=1), f'{crop}_Cluster'] = labels\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Optimal number of clusters for {crop}: {optimal_k}')\n",
    "    print(f'Silhouette scores for {crop}: {scores}')\n",
    "    \n",
    "    # Visualize the silhouette scores\n",
    "    plt.plot(range(2, 11), scores, marker='o')\n",
    "    plt.title(f'Silhouette Scores for {crop}')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize the clustering results\n",
    "    plt.scatter(df_agg_00_23[f'{crop}_mean'], df_agg_00_23[f'{crop}_std'], c=df_agg_00_23[f'{crop}_Cluster'], cmap='viridis')\n",
    "    plt.title(f'Spectral Clustering Results for {crop}')\n",
    "    plt.xlabel(f'{crop}_mean')\n",
    "    plt.ylabel(f'{crop}_std')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Clusters by Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# Assuming df_agg_00_23 is already loaded\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Function to prepare data for each crop\n",
    "def prepare_data_for_crop(df, crop):\n",
    "    columns = [f'{crop}_mean', f'{crop}_std']\n",
    "    crop_data = df[columns].dropna().values\n",
    "    return crop_data, df[columns].dropna().index\n",
    "\n",
    "# Standardize the data\n",
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled\n",
    "\n",
    "# Perform spectral clustering with a fixed number of clusters\n",
    "def perform_spectral_clustering(data, n_clusters=5):\n",
    "    clustering = SpectralClustering(n_clusters=n_clusters, assign_labels=\"discretize\", random_state=0)\n",
    "    labels = clustering.fit_predict(data)\n",
    "    return labels\n",
    "\n",
    "# Iterate over each crop and perform clustering\n",
    "for crop in crops:\n",
    "    # Prepare the data for the crop\n",
    "    crop_data, indices = prepare_data_for_crop(df_agg_00_23, crop)\n",
    "    \n",
    "    # Standardize the data\n",
    "    crop_data_scaled = standardize_data(crop_data)\n",
    "    \n",
    "    # Perform spectral clustering with 5 clusters\n",
    "    labels = perform_spectral_clustering(crop_data_scaled, 5)\n",
    "    \n",
    "    # Add the cluster labels to the original dataframe\n",
    "    df_agg_00_23[f'{crop}_Cluster_Spectral'] = np.nan\n",
    "    df_agg_00_23.loc[indices, f'{crop}_Cluster_Spectral'] = labels\n",
    "\n",
    "# Display the dataframe with the new cluster columns\n",
    "df_agg_00_23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualizing Clustering Raw Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(gdf_rm_clean.rename(columns={'RMNO':'RM'}),\n",
    "         df_agg_00_23,\n",
    "          on='RM' )\\\n",
    "            .explore('Canola_Cluster_Spectral',\n",
    "                     cmap='RdYlGn',\n",
    "                     scheme='naturalbreaks',\n",
    "                     k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualizing Ranked Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking by historical yield\n",
    "df_agg_00_23.groupby('Canola_Cluster_Spectral').mean()['Canola_mean'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking Clusters based on mean\n",
    "clusters_to_replace_canola= {\n",
    "    2:0,\n",
    "    4:1,\n",
    "    0:2,\n",
    "    3:3,\n",
    "    1:4\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df_agg_00_23['Canola_Cluster_Spectral']=df_agg_00_23['Canola_Cluster_Spectral'].replace(to_replace=clusters_to_replace_canola)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(gdf_rm_clean.rename(columns={'RMNO':'RM'}),\n",
    "         df_agg_00_23,\n",
    "          on='RM' )\\\n",
    "            .explore('Canola_Cluster_Spectral',\n",
    "                     cmap='RdYlGn',\n",
    "                     scheme='naturalbreaks',\n",
    "                     k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df_agg_00_23 is already loaded\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Function to prepare data for each crop\n",
    "def prepare_data_for_crop(df, crop):\n",
    "    columns = [f'{crop}_mean', f'{crop}_std']\n",
    "    crop_data = df[columns].dropna().values\n",
    "    return crop_data, df[columns].dropna().index\n",
    "\n",
    "# Standardize the data\n",
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled\n",
    "\n",
    "# Function to perform K-Means clustering\n",
    "def kmeans_clustering(data, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    labels = kmeans.fit_predict(data)\n",
    "    return labels\n",
    "\n",
    "# Function to find the optimal number of clusters using the Elbow method\n",
    "def find_optimal_clusters(data, max_k):\n",
    "    distortions = []\n",
    "    for k in range(1, max_k+1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "        kmeans.fit(data)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "    optimal_k = distortions.index(min(distortions[1:])) + 1\n",
    "    return optimal_k, distortions\n",
    "\n",
    "# Iterate over each crop and perform clustering\n",
    "for crop in crops:\n",
    "    # Prepare the data for the crop\n",
    "    crop_data, indices = prepare_data_for_crop(df_agg_00_23, crop)\n",
    "    \n",
    "    # Standardize the data\n",
    "    crop_data_scaled = standardize_data(crop_data)\n",
    "    \n",
    "    # Find the optimal number of clusters using the Elbow method\n",
    "    optimal_k, distortions = find_optimal_clusters(crop_data_scaled, 10)\n",
    "    \n",
    "    # Perform K-Means clustering with the optimal number of clusters\n",
    "    optimal_labels = kmeans_clustering(crop_data_scaled, optimal_k)\n",
    "    \n",
    "    # Perform K-Means clustering with 5 clusters\n",
    "    fixed_labels = kmeans_clustering(crop_data_scaled, 5)\n",
    "    \n",
    "    # Add the cluster labels to the original dataframe\n",
    "    df_agg_00_23[f'{crop}_Optimal_Cluster_KMeans'] = np.nan\n",
    "    df_agg_00_23[f'{crop}_Fixed_Cluster_KMeans'] = np.nan\n",
    "    df_agg_00_23.loc[indices, f'{crop}_Optimal_Cluster_KMeans'] = optimal_labels\n",
    "    df_agg_00_23.loc[indices, f'{crop}_Fixed_Cluster_KMeans'] = fixed_labels\n",
    "    \n",
    "    # Plot the Elbow method graph\n",
    "    plt.plot(range(1, 11), distortions, marker='o')\n",
    "    plt.title(f'Elbow Method for {crop}')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.show()\n",
    "\n",
    "# Display the dataframe with the new cluster columns\n",
    "df_agg_00_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(gdf_rm_clean.rename(columns={'RMNO':'RM'}),\n",
    "         df_agg_00_23,\n",
    "          on='RM' )\\\n",
    "            .explore('Canola_Fixed_Cluster_KMeans',\n",
    "                     cmap='RdYlGn',\n",
    "                     scheme='naturalbreaks',\n",
    "                     k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranked KMeans Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking by historical yield\n",
    "df_agg_00_23.groupby('Canola_Fixed_Cluster_KMeans').mean()['Canola_mean'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking Clusters based on mean\n",
    "clusters_to_replace_canola_kmeans= {\n",
    "    4:0,\n",
    "    2:1,\n",
    "    1:2,\n",
    "    0:3,\n",
    "    3:4\n",
    "}\n",
    "\n",
    "df_agg_00_23['Canola_Fixed_Cluster_KMeans']=df_agg_00_23['Canola_Fixed_Cluster_KMeans']\\\n",
    "    .replace(to_replace=clusters_to_replace_canola_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(gdf_rm_clean.rename(columns={'RMNO':'RM'}),\n",
    "         df_agg_00_23,\n",
    "          on='RM' )\\\n",
    "            .explore('Canola_Fixed_Cluster_KMeans',\n",
    "                     cmap='RdYlGn',\n",
    "                     scheme='naturalbreaks',\n",
    "                     k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
